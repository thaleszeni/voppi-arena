import { COMPANY_CONTEXT } from './companyContext';
import { getEnrichedProfile, generatePromptContext, generateResponseRules } from './personaProfiles';

const SIMULATION_RESPONSES = {
    'skeptical': [
        "Olha, eu j√° recebi v√°rias liga√ß√µes dessa. O que voc√™s t√™m de diferente?",
        "N√£o estou convencido de que isso traga retorno real para o meu restaurante.",
        "Muitas taxas. Como eu sei que n√£o vou perder dinheiro?",
        "J√° uso outros apps e eles me d√£o muito trabalho.",
        "O pessoal do Prime Gourmet j√° passou aqui e a conta n√£o fechou."
    ],
    'busy': [
        "Estou no meio do servi√ßo agora, pode ser r√°pido?",
        "Temos muito movimento hoje. O que voc√™ quer exatamente?",
        "N√£o tenho tempo para apresenta√ß√µes longas.",
        "Se for para vender an√∫ncio, eu n√£o quero.",
        "Estou com a cozinha cheia, me liga em outra hora?"
    ],
    'innovator': [
        "Interessante... como funciona a integra√ß√£o com meu sistema?",
        "Estou buscando novas formas de atrair p√∫blico jovem.",
        "Voc√™s trabalham com algum tipo de automa√ß√£o?",
        "Me conte mais sobre como a Voppi ajuda no meu marketing.",
        "Vi algo parecido em S√£o Paulo, voc√™s atendem essa regi√£o?"
    ]
};

const LEAD_NAMES = ["Ricardo", "Patr√≠cia", "S√©rgio", "M√°rcia", "Fernando", "Cl√°udia", "Roberto", "Silvana"];

export async function getAIResponse(messages, scenarioContext) {
    const apiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;

    if (apiKey) {
        return callRealLLM(messages, scenarioContext, apiKey);
    } else {
        return callSimulation(messages, scenarioContext);
    }
}

async function callRealLLM(messages, scenarioContext, apiKey) {
    try {
        // üîç DEBUG: Log para verificar se enrichedProfileId est√° chegando
        console.log('[AI Debug] Scenario context:', {
            title: scenarioContext.title,
            enrichedProfileId: scenarioContext.enrichedProfileId,
            hasProfile: !!scenarioContext.enrichedProfileId
        });

        // Tenta carregar perfil enriquecido se existir
        const enrichedProfile = scenarioContext.enrichedProfileId
            ? getEnrichedProfile(scenarioContext.enrichedProfileId)
            : null;

        let systemPrompt = "";

        if (enrichedProfile) {
            // ========== PROMPT AVAN√áADO COM CONTEXTO RICO ==========
            const contextBlock = generatePromptContext(enrichedProfile);
            const rulesBlock = generateResponseRules(enrichedProfile);

            systemPrompt = `
Voc√™ √© um LEAD REAL√çSTICO em uma cold call de vendas. Sua tarefa √© atuar como ${enrichedProfile.decisionMaker.name}, atendendo o telefone no seu estabelecimento.

${contextBlock}

${rulesBlock}

INFORMA√á√ïES SOBRE O QUE EST√ÉO TE VENDENDO (VOPPI):
${COMPANY_CONTEXT.valueProposition}

Modelo de neg√≥cio: ${COMPANY_CONTEXT.distributionAndMarketing}
Pricing: ${COMPANY_CONTEXT.pricing}

==========================================
INSTRU√á√ïES CR√çTICAS DE ATUA√á√ÉO:
==========================================

1Ô∏è‚É£ COER√äNCIA ABSOLUTA:
   - SEMPRE responda ao que o vendedor acabou de dizer
   - N√ÉO ignore perguntas ou informa√ß√µes dele
   - Se ele mencionar algo espec√≠fico do SEU neg√≥cio (ex: Instagram, dias fracos), RECONHE√áA isso

2Ô∏è‚É£ MEM√ìRIA CONVERSACIONAL:
   - Lembre do que J√Å foi dito na conversa
   - Se voc√™ j√° perguntou algo, n√£o pergunte de novo
   - Se ele j√° se apresentou, n√£o pergunte o nome novamente

3Ô∏è‚É£ NATURALIDADE:
   - M√°ximo 2 frases por resposta (voc√™ est√° ocupado)
   - Use detalhes do SEU estabelecimento (${enrichedProfile.businessProfile.name})
   - Fale como uma pessoa real, n√£o como chatbot
   - Pode interromper se ele enrolar muito

4Ô∏è‚É£ REA√á√ïES CONTEXTUAIS:
   ${enrichedProfile.interestTriggers.positive.map((t, i) => `   ${String.fromCharCode(97 + i)}) Se ele ${t.toLowerCase()} ‚Üí mostre um pouco mais de interesse`).join('\n')}
   
   ${enrichedProfile.interestTriggers.negative.map((t, i) => `   ${String.fromCharCode(97 + i)}) Se ele ${t.toLowerCase()} ‚Üí fique mais seco e desconfiado`).join('\n')}

5Ô∏è‚É£ EXEMPLOS DE BOAS RESPOSTAS:
   ‚ùå RUIM: "N√£o tenho interesse."
   ‚úÖ BOM: "Olha, t√° corrido aqui. O que voc√™ quer?"
   
   ‚ùå RUIM: "Me manda no WhatsApp."
   ‚úÖ BOM: "Quarta-feira √© meu dia mais fraco mesmo... mas o que voc√™s fazem diferente do iFood?"

==========================================
            `.trim();
        } else {
            // ========== PROMPT B√ÅSICO (FALLBACK) ==========
            const leadName = LEAD_NAMES[Math.floor(Math.random() * LEAD_NAMES.length)];

            systemPrompt = `
Voc√™ √© um lead comercial REAL√çSTICO (${COMPANY_CONTEXT.segment}).
Seu nome √© ${leadName}. 
No momento voc√™ √©: ${scenarioContext.leadType?.name || 'um propriet√°rio de estabelecimento'}.

ESTILO DE CONVERSA:
- Aja como se estivesse atendendo o telefone no seu neg√≥cio (pode haver barulho de fundo).
- N√£o fale como um rob√¥. Fale como uma pessoa real.
- Seja direto: donos de neg√≥cios t√™m pouco tempo.
- SEMPRE responda ao que foi perguntado.

SOBRE SEU NEG√ìCIO:
- P√∫blico: ${COMPANY_CONTEXT.targetAudience}
- Dificuldades: ${COMPANY_CONTEXT.mainObjections.join(', ')}

O QUE EST√ÉO TE VENDENDO (VOPPI):
${COMPANY_CONTEXT.valueProposition}

SUA PERSONA:
- Perfil: ${scenarioContext.leadType?.description || 'Exigente com custos e resultados'}.
- Objetivo: Agir como o lead no cen√°rio "${scenarioContext.title}".

REGRAS DE OURO:
1. M√°ximo 2 frases por resposta.
2. N√£o d√™ seu nome de cara se n√£o confia no vendedor.
3. Se o vendedor for vago ou "vendedorz√£o" demais, seja mais seco.
4. Se ele citar um "case" ou algo espec√≠fico do seu Instagram, mostre um pouco mais de aten√ß√£o.
5. Use g√≠rias corporativas de forma leve.
6. SEMPRE responda ao que o vendedor realmente disse, n√£o ignore perguntas.
            `.trim();
        }

        // Preparar hist√≥rico da conversa
        const historyContext = messages.map(m => `${m.role === 'user' ? 'Vendedor' : 'Voc√™ (Lead)'}:  ${m.content}`).join('\n');

        // An√°lise r√°pida do √∫ltimo contexto para refor√ßar coer√™ncia
        const lastUserMessage = messages[messages.length - 1]?.content || "";
        const coherenceCheck = `
        
‚ö†Ô∏è O VENDEDOR ACABOU DE DIZER: "${lastUserMessage}"
‚Üí Sua resposta DEVE reagir diretamente a isso. N√£o mude de assunto.
        `.trim();

        const finalPrompt = `${systemPrompt}\n\n${'='.repeat(60)}\nHIST√ìRICO DA CONVERSA:\n${'='.repeat(60)}\n${historyContext}\n\n${coherenceCheck}\n\nSua resposta (m√°x 2 frases):`;

        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent?key=${apiKey}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                contents: [{
                    parts: [{ text: finalPrompt }]
                }],
                generationConfig: {
                    temperature: 0.8,  // Um pouco de variabilidade natural
                    topP: 0.95,
                    topK: 40,
                    maxOutputTokens: 150  // For√ßar respostas curtas
                }
            })
        });

        const data = await response.json();

        if (data.error) {
            console.error("Gemini API Error:", data.error);
            return callSimulation(messages, scenarioContext);
        }

        let aiResponse = data.candidates[0].content.parts[0].text.trim();

        // Limpar poss√≠veis artefatos de formata√ß√£o
        aiResponse = aiResponse.replace(/^(Lead|Voc√™ \(Lead\)|Ricardo|Patr√≠cia):?\s*/i, '').trim();

        return aiResponse;
    } catch (err) {
        console.error("AI Error:", err);
        return callSimulation(messages, scenarioContext);
    }
}

function callSimulation(messages, scenarioContext) {
    const lastUserMsg = messages[messages.length - 1].content.toLowerCase();
    const historyCount = messages.filter(m => m.role === 'assistant').length;
    const type = scenarioContext.leadType?.id || 'skeptical';
    const responses = SIMULATION_RESPONSES[type] || SIMULATION_RESPONSES.skeptical;

    // Greeting logic
    if (historyCount <= 1) {
        if (lastUserMsg.includes('nome') || lastUserMsg.includes('quem fala')) {
            return `Aqui √© o ${LEAD_NAMES[0]}. O que voc√™ quer exatamente?`;
        }
    }

    // Keyword logic with more variety
    if (lastUserMsg.includes('pre√ßo') || lastUserMsg.includes('taxa') || lastUserMsg.includes('quanto custa')) {
        return "Todo mundo fala que n√£o tem custo, mas sempre tem uma pegadinha. Qual a porcentagem de voc√™s?";
    }
    if (lastUserMsg.includes('ol√°') || lastUserMsg.includes('bom dia') || lastUserMsg.includes('boa tarde')) {
        if (historyCount > 1) return "Como eu disse, estou corrido. Pode ir direto ao ponto?";
        return "Opa, tudo bem? Quem fala?";
    }
    if (lastUserMsg.includes('parceria') || lastUserMsg.includes('ajudar')) {
        return "Cara, recebo 5 liga√ß√µes de 'parceria' por dia. O que a Voppi faz que o Instagram sozinho n√£o faz?";
    }
    if (lastUserMsg.includes('agendar') || lastUserMsg.includes('reuni√£o') || lastUserMsg.includes('visita')) {
        return "N√£o quero agendar nada antes de entender se isso faz sentido pro meu caixa. Me explica mais aqui.";
    }

    // Default random from persona with simple rotation to avoid repetition
    return responses[messages.length % responses.length];
}

export async function evaluateRoleplay(history, scenarioContext) {
    const apiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;

    // Default fallback structure
    const fallbackResult = {
        scores: { strategy: 50, clarity: 50, tone: 50, diagnosis: 50, closing: 50 },
        feedback: "Houve um erro na avalia√ß√£o. Tente novamente.",
        totalXP: 50
    };

    try {
        // If we have an API key, use it for a much better evaluation
        if (apiKey) {
            try {
                const historyText = history.map(m => `${m.role === 'user' ? 'Vendedor' : 'Lead'}: ${m.content}`).join('\n');
                const guidelines = COMPANY_CONTEXT.salesGuidelines || {};

                const prompt = `
                Voc√™ √© um treinador de vendas s√™nior da Voppi. Avalie a seguinte conversa de roleplay.
                
                CONTEXTO VOPPI:
                ${COMPANY_CONTEXT.valueProposition}
                
                DIRETRIZES DE SUCESSO DO TIME COMERCIAL:
                Objetivo: ${guidelines.coldCallGoal || 'Agendar reuni√£o'}
                O que √© BOM:
                ${(guidelines.whatGoodSoundsLike || []).join('\n- ')}
                
                O que √© RUIM:
                ${(guidelines.whatBadSoundsLike || []).join('\n- ')}
                
                CONVERSA:
                ${historyText}
                
                TAREFA:
                Avalie o Vendedor e retorne APENAS um JSON (sem markdown) no seguinte formato:
                {
                    "scores": {
                        "strategy": 0-100, // Seguiu o processo?
                        "clarity": 0-100, // Foi claro sobre a proposta?
                        "tone": 0-100, // Foi educado e firme?
                        "diagnosis": 0-100, // Fez perguntas ou s√≥ falou?
                        "closing": 0-100 // Tentou fechar/agendar?
                    },
                    "feedback": "Uma frase resumindo o desempenho e uma dica pr√°tica baseada no erro principal."
                }
            `;

                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: prompt }] }]
                    })
                });

                const data = await response.json();
                const text = data.candidates[0].content.parts[0].text;

                // Clean markdown if present
                const jsonStr = text.replace(/```json/g, '').replace(/```/g, '').trim();
                const result = JSON.parse(jsonStr);

                // Calculate total XP based on avg score
                const avg = Object.values(result.scores).reduce((a, b) => a + b, 0) / 5;

                return {
                    scores: result.scores,
                    feedback: result.feedback,
                    totalXP: Math.round(avg * 2.5) // Scale up slightly
                };

            } catch (err) {
                console.error("AI Eval Error:", err);
                // Fallback to heuristics below
            }
        }

        const userMessages = history.filter(m => m.role === 'user');
        const lastMessage = userMessages[userMessages.length - 1]?.content.toLowerCase() || '';

        // Default scores
        let scores = {
            strategy: 50,
            clarity: 50,
            tone: 50,
            diagnosis: 20,
            closing: 20
        };

        // Heuristics
        const totalWords = userMessages.reduce((acc, msg) => acc + msg.content.split(' ').length, 0);
        const avgWords = totalWords / (userMessages.length || 1);

        // 1. Clarity: Short messages are better in chat
        if (avgWords < 20) scores.clarity += 20;
        if (avgWords < 10) scores.clarity += 10;

        // 2. Diagnosis: Asking questions
        const questionCount = userMessages.filter(m => m.content.includes('?')).length;
        scores.diagnosis += Math.min(questionCount * 15, 60); // Max 80 total

        // 3. Tone: Politeness keywords
        const politeWords = ['obrigado', 'por favor', 'entendo', '√≥timo', 'certo'];
        const hasPolite = userMessages.some(m => politeWords.some(w => m.content.toLowerCase().includes(w)));
        if (hasPolite) scores.tone += 30;

        // 4. Closing: Action words in the end
        const closingWords = ['agendar', 'reuni√£o', 'visita', 'amanh√£', 'semana que vem', 'demo'];
        if (closingWords.some(w => lastMessage.includes(w))) {
            scores.closing += 60;
            scores.strategy += 20;
        }

        // 5. Strategy: Engagement length (too short = bad, too long = bad)
        if (userMessages.length >= 3 && userMessages.length <= 8) scores.strategy += 20;

        // Cap scores at 100
        Object.keys(scores).forEach(k => scores[k] = Math.min(100, scores[k]));

        const totalXP = Math.round(
            (scores.strategy + scores.clarity + scores.tone + scores.diagnosis + scores.closing) / 5 * 2 // ~200 XP avg
        );

        let feedback = "Bom esfor√ßo! ";
        if (scores.closing < 50) feedback += "Voc√™ precisa tentar fechar a venda ou agendar um pr√≥ximo passo no final. ";
        if (scores.diagnosis < 50) feedback += "Fa√ßa mais perguntas para entender o cliente. ";
        if (scores.clarity > 80) feedback += "Sua comunica√ß√£o foi direta e clara. Parab√©ns!";

        return {
            scores,
            feedback,
            totalXP
        };
    } catch (err) {
        console.error("Critical Error in evaluateRoleplay:", err);
        return fallbackResult;
    }
}
